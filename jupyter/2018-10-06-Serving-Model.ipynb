{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to serve a model\n",
    "\n",
    "Here we show how to:\n",
    "1. train a model\n",
    "2. save it to pickle\n",
    "3. load a model and serve it with `aiohttp`.\n",
    "\n",
    "In order to keep it simple we are going to use a `sklearn` model.\n",
    "\n",
    "## Getting data\n",
    "\n",
    "Dataset `train.csv` comes from kaggle: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge. We locally store in `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comments_df = pd.read_csv(\"data/toxic-comment-classification-challenge/train.csv\")\n",
    "comments_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict if comment is toxic\n",
    "\n",
    "### Train - validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34852</th>\n",
       "      <td>This is a straw man argument, Mr Merkey.  Nobo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17133</th>\n",
       "      <td>ARC Gritt, the fucking cunt of all cunts, ruin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_text\n",
       "34852  This is a straw man argument, Mr Merkey.  Nobo...\n",
       "17133  ARC Gritt, the fucking cunt of all cunts, ruin..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(comments_df[['comment_text']], comments_df['toxic'], random_state=10)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and vectorizer\n",
    "\n",
    "Let's do some simple preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "GOOD_SYMBOLS = \"â‚¬\\?\"\n",
    "GOOD_SYMBOLS_RE = re.compile('([' + GOOD_SYMBOLS + '])')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z '+ GOOD_SYMBOLS + ']')\n",
    "ADD_SPACES_SYMBOLS_RE = re.compile(\"([\\?])\")\n",
    "STEMMER = SnowballStemmer('english')\n",
    "\n",
    "class TextPreprocessor:\n",
    "        \n",
    "    def transfrom_text(self, text):\n",
    "        text = re.sub(GOOD_SYMBOLS_RE, r\"\\1\", text) #process good symbols\n",
    "        text = text.lower()\n",
    "        text = re.sub(REPLACE_BY_SPACE_RE, \" \", text) # process bad symbols\n",
    "        text = re.sub(BAD_SYMBOLS_RE, \"\", text) # process bad symbols\n",
    "        text = re.sub(ADD_SPACES_SYMBOLS_RE, r\" \\1 \", text)\n",
    "        test = \" \".join([STEMMER.stem(word) for word in text.split()])\n",
    "        return text\n",
    "    \n",
    "    def transform(self, series):\n",
    "        return series.apply(lambda text: self.transfrom_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class Vectorizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(min_df=4, max_df=0.9, ngram_range=(1, 2), token_pattern='(\\S+)')\n",
    "        self.pickle_fn = \"pickles/messaging_vectorizer.pickle\"\n",
    "        \n",
    "    def fit(self, column):\n",
    "        self.vectorizer.fit(column)\n",
    "        \n",
    "    def transform(self, column):\n",
    "        return self.vectorizer.transform(column)\n",
    "    \n",
    "    def dumps(self):\n",
    "        with open(self.pickle_fn, 'wb') as f:\n",
    "            pickle.dump(self.vectorizer, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    def load(self):\n",
    "        with open(self.pickle_fn, 'rb') as f:\n",
    "            self.vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "class Model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression(class_weight='balanced')\n",
    "        self.pickle_fn = \"pickles/messaging_model.pickle\"\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def dumps(self):\n",
    "        with open(self.pickle_fn, 'wb') as f:\n",
    "            pickle.dump(self.model, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    def load(self):\n",
    "        with open(self.pickle_fn, 'rb') as f:\n",
    "            self.model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,\\\n",
    "    average_precision_score, roc_auc_score, recall_score\n",
    "\n",
    "def scores(y, predicted):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y, predicted),\n",
    "        'precision': precision_score(y, predicted),\n",
    "        'recall': recall_score(y, predicted),\n",
    "        'f1-score': f1_score(y, predicted),\n",
    "        \"roc_auc\": roc_auc_score(y, predicted),\n",
    "        'average-Precision': average_precision_score(y, predicted)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puting preprocessor, vectorizer and model together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfModelAll:\n",
    "    \n",
    "    def __init__(self, colname=\"text\"):\n",
    "        self.colname = colname\n",
    "        self.preprocessor = TextPreprocessor()\n",
    "        self.vectorizer = Vectorizer()\n",
    "        self.model = Model()\n",
    "           \n",
    "    def fit_predict(self, X, y):\n",
    "        print(\"preprocessor...\")\n",
    "        X_fe = pd.DataFrame({self.colname: self.preprocessor.transform(X[self.colname])})\n",
    "        print(\"vectorizer...\")\n",
    "        self.vectorizer.fit(X_fe[self.colname])\n",
    "        print(\"model...\")\n",
    "        X_fe = self.vectorizer.transform(X[self.colname])\n",
    "        self.model.fit(X_fe, y)\n",
    "        return self.model.predict(X_fe)\n",
    "        \n",
    "    def predict(self, X=None, message=None):\n",
    "        if message is not None:\n",
    "            X = pd.DataFrame({self.colname: [message]})\n",
    "        X_fe = pd.DataFrame({self.colname: self.preprocessor.transform(X[self.colname])})        \n",
    "        X_fe = self.vectorizer.transform(X_fe[self.colname])\n",
    "        return self.model.predict(X_fe)\n",
    "    \n",
    "    def predict_message(self, message):\n",
    "        return self.predict(message=message)[0]\n",
    "        \n",
    "    def dumps(self):\n",
    "        self.vectorizer.dumps()\n",
    "        self.model.dumps()\n",
    "    \n",
    "    def load(self):\n",
    "        self.vectorizer.load()\n",
    "        self.model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, validate it and save the model to a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessor...\n",
      "vectorizer...\n",
      "model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.953358177777035,\n",
       " 'average-Precision': 0.6641958777165086,\n",
       " 'f1-score': 0.8007424858999072,\n",
       " 'precision': 0.6819066147859922,\n",
       " 'recall': 0.969738889849559,\n",
       " 'roc_auc': 0.96067231602142}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model = TfidfModelAll(\"comment_text\")\n",
    "y_train_hat = tfidf_model.fit_predict(X_train, y_train)\n",
    "scores(y_train, y_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9331963001027749,\n",
       " 'average-Precision': 0.5239641176536308,\n",
       " 'f1-score': 0.7035265324285237,\n",
       " 'precision': 0.6010264208325413,\n",
       " 'recall': 0.848175965665236,\n",
       " 'roc_auc': 0.8950682123362819}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_hat = tfidf_model.predict(X_val)\n",
    "scores(y_val, y_val_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.dumps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving model\n",
    "\n",
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model2 = TfidfModelAll(\"comment_text\")\n",
    "tfidf_model2.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9331963001027749,\n",
       " 'average-Precision': 0.5239641176536308,\n",
       " 'f1-score': 0.7035265324285237,\n",
       " 'precision': 0.6010264208325413,\n",
       " 'recall': 0.848175965665236,\n",
       " 'roc_auc': 0.8950682123362819}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_hat = tfidf_model2.predict(X_val)\n",
    "scores(y_val, y_val_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"\"\"All of my edits are good. \n",
    "Cunts like you who revert good edits because you're too stupid to understand how to write well , \n",
    "and then revert other edits just because you've decided to bear a playground grudge, are the problem.  \n",
    "Maybe one day you'll realise the damage you did to a noble project.  201.215.187.159\"\"\"\n",
    "tfidf_model2.predict_message(message=message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "asyncio.get_event_loop().close()\n",
    "print(asyncio.get_event_loop().is_closed())\n",
    "loop = asyncio.new_event_loop()\n",
    "asyncio.set_event_loop(asyncio.new_event_loop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Running on http://0.0.0.0:8080 ========\n",
      "(Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from aiohttp import web\n",
    "\n",
    "async def handler(request):\n",
    "    data = await request.post()\n",
    "    message = data.get(\"message\") \n",
    "    prediction = tfidf_model2.predict_message(message=message)\n",
    "    return web.Response(text=str(prediction))\n",
    "\n",
    "app = web.Application()\n",
    "\n",
    "app.add_routes([web.post('/toxic', handler)])\n",
    "web.run_app(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how it work\n",
    "\n",
    "From command line execute the following:\n",
    "```\n",
    "curl -X POST http://0.0.0.0:8080/toxic -d \"message=All of my edits are good.                               \n",
    "Cunts like you who revert good edits because you're too stupid to understand how to write well ,\n",
    "and then revert other edits just because you've decided to bear a playground grudge, are the problem.\n",
    "Maybe one day you'll realise the damage you did to a noble project.  201.215.187.159\"\n",
    "```\n",
    "\n",
    "\n",
    "## Thanks\n",
    "\n",
    "I would like to thank Luca Cerone (<http://www.lucacerone.net/>) for helpfull conversation and suggesting usage of `aiohttp` instead of `flask`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
