{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will explain what we can do when we deal with categorical variables. That is variables that are not numeric.\n",
    "\n",
    "## Labelizer\n",
    "\n",
    "The easiest way to deal with them is to just transform them into numbers. Let's look at the following example.\n",
    "\n",
    "__Example__ Let's assume that one of our column contains names of animals. There are three of them _dog_, _cat_ and _horse_. We can then assign them numbers: 0, 1 and 2. Hence we have transformed categorical variable into numeric one. Let's look how we can do this in `python`.\n",
    "\n",
    "So let's put all out classes as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"dog\", \"cat\", \"horse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our categories have a numeration. That is on order in the list. So we can easily create a dictionary that transform an animal name into a number:\n",
    "* dog to 0\n",
    "* cat to 1\n",
    "* horse to 2.\n",
    "\n",
    "In python it can be done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2num = {categories[i]: i for i in range(len(categories))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we can transform a column of a `DataFrame` using this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_df = pd.DataFrame({\"name\": [\"dog\", \"dog\", \"cat\", \"dog\", \"horse\", \"cat\", \"dog\"]})\n",
    "animals_df[\"name_label\"] = animals_df[\"name\"].apply(lambda name: col2num[name])\n",
    "animals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important problem with this kind of encoding is that there is no natural order of those categories. There is reason why _cat_ should go between _dog_ and _horse_. This could cause a problem when we try to do linear regression. We will see it in the following example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Let's train a model of prices of houses using `Neighborhood` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv(\"data/house-prices-advanced-regression-techniques/train.csv\", index_col=\"Id\")\n",
    "\n",
    "target_col = \"SalePrice\"\n",
    "categorical_column = \"Neighborhood\"\n",
    "Xy = houses[[categorical_column, target_col]]\n",
    "X = Xy.drop(target_col, axis=1)\n",
    "y = Xy[target_col]\n",
    "\n",
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, random_state=666, test_size=0.2)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, random_state=667, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = X[categorical_column].unique()\n",
    "col2num = {classes[i]: i for i in range(len(classes))}\n",
    "X_train[categorical_column + \"_label\"] = X_train[categorical_column].apply(lambda cls: col2num[cls])\n",
    "X_dev[categorical_column + \"_label\"] = X_dev[categorical_column].apply(lambda cls: col2num[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train[[categorical_column + \"_label\"]], y_train)\n",
    "y_dev_hat = reg.predict(X_dev[[categorical_column + \"_label\"]])\n",
    "print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's see why adding sort of random numbers to categories is not the best idea. We will plot the prediction and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting real data y (blue)\n",
    "plt.scatter(X_dev[[categorical_column + \"_label\"]], y_dev, alpha=0.3, c=\"blue\")\n",
    "# versus predicted y_hat (red)\n",
    "\n",
    "\n",
    "plt.plot(X_dev[[categorical_column + \"_label\"]], y_dev_hat, alpha=0.3, c=\"red\")\n",
    "\n",
    "plt.xlabel(\"Labelized category\")\n",
    "plt.ylabel(\"Sale Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that prediction is almost constant and we probably should reorder labels in a different ways. There two ways of solving it that we will discuss here.\n",
    "1. We could labelized categories in a way that they do not have an order. We can do this using One-Hot-Encoding.\n",
    "2. Labelized categories by numbers that makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot-Encoding \n",
    "\n",
    "Let's comeback to animals example. The way to labelized categories in the way that they will not have any order is called One-Hot-Encoding. It is done by creating that many columns as categories we have and fill them with zeros, except the one that corresponds the category. So encode categories as follows:\n",
    "* dog to `[1, 0, 1]`\n",
    "* cat to `[0, 1, 0]`\n",
    "* horse to `[0, 0, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_one_hot_encoding(series, dict_length=None):\n",
    "    if dict_length is None:\n",
    "        dict_length = len(series.unique())\n",
    "    return np.eye(dict_length)[series]\n",
    "\n",
    "print(animals_df)\n",
    "print(label_one_hot_encoding(animals_df[\"name_label\"], len(categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train it and see it it's get better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_length = len(X_train[categorical_column + \"_label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(label_one_hot_encoding(X_train[categorical_column + \"_label\"], dict_length), y_train)\n",
    "y_dev_hat = reg.predict(label_one_hot_encoding(X_dev[categorical_column + \"_label\"], dict_length))\n",
    "print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value encoding\n",
    "\n",
    "Another way of encoding categories is to use average values of target variable. Actually in this situation we will get exactly the same predictions `y_dev_hat`. The most important think to remember is to use `X_train` and `y_train`. Let's see with the following code what it means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_value_df = X_train[[categorical_column]]\n",
    "category_value_df[categorical_column+\"_value\"] = y_train\n",
    "category_value_df = category_value_df.groupby(categorical_column, as_index=False).mean()\n",
    "category_value_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_hat_value_encoded = \\\n",
    "    X_dev.merge(category_value_df, how=\"left\", on=categorical_column)[[categorical_column+\"_value\"]]\n",
    "print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['OverallQual', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', \n",
    "'TotalBsmtSF', \"Neighborhood\", \"ExterQual\"]\n",
    "\n",
    "target_col = \"SalePrice\"\n",
    "X = houses[columns]\n",
    "y = houses[target_col]\n",
    "\n",
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, random_state=666, test_size=0.2)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, random_state=667, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Labelizer:\n",
    "    \n",
    "    def __init__(self, categories):\n",
    "        self.categories = categories\n",
    "        self.cat2num = {}\n",
    "        self.num2cat = {}\n",
    "        \n",
    "    def generate_dicts(self):\n",
    "        self.cat2num = {self.categories[i]: i for i in range(len(self.categories))}\n",
    "        self.num2cat = {i: self.categories[i] for i in range(len(self.categories))}\n",
    "        \n",
    "    def fit(self):\n",
    "        self.generate_dicts()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, series):\n",
    "        return series.apply(lambda cat: self.cat2num[cat])\n",
    "    \n",
    "labelizer_Neighborhood = Labelizer(X_train[\"Neighborhood\"].unique()).fit()  \n",
    "labelizer_ExterQual = Labelizer(X_train[\"ExterQual\"].unique()).fit()\n",
    "\n",
    "def labelize_X(X):\n",
    "    labelized_X = X.drop([\"Neighborhood\", \"ExterQual\"], axis=1)\n",
    "    labelized_X[\"Neighborhood_labelized\"] = labelizer_Neighborhood.transform(X[\"Neighborhood\"])\n",
    "    labelized_X[\"ExterQual_labelized\"] = labelizer_ExterQual.transform(X[\"ExterQual\"])\n",
    "    return labelized_X\n",
    "\n",
    "X_train_labelized = labelize_X(X_train)\n",
    "X_dev_labelized = labelize_X(X_dev)\n",
    "\n",
    "reg.fit(X_train_labelized, y_train)\n",
    "y_dev_hat = reg.predict(X_dev_labelized)\n",
    "print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "B = np.array([[7], [8], [9]])\n",
    "C = np.array([[11, 12], [13, 14], [16, 15]])\n",
    "np.concatenate([A, B, C], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoderWithLabelizer:\n",
    "    \n",
    "    def __init__(self, categories):\n",
    "        self.categories = categories\n",
    "        self.labelizer = Labelizer(categories)\n",
    "            \n",
    "    def fit(self):\n",
    "        self.labelizer.fit()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, series):\n",
    "        series_labelized = self.labelizer.transform(series)\n",
    "        return np.eye(len(self.categories))[series_labelized]\n",
    "    \n",
    "one_hot_encoder_Neighborhood = OneHotEncoderWithLabelizer(X_train[\"Neighborhood\"].unique()).fit()  \n",
    "one_hot_encoder_ExterQual = OneHotEncoderWithLabelizer(X_train[\"ExterQual\"].unique()).fit()\n",
    "\n",
    "def one_hot_encode_X(X):\n",
    "    X_other = X.drop([\"Neighborhood\", \"ExterQual\"], axis=1).as_matrix()\n",
    "    neighborhood_encoded = one_hot_encoder_Neighborhood.transform(X[\"Neighborhood\"])\n",
    "    exterQual_encoded = one_hot_encoder_ExterQual.transform(X[\"ExterQual\"])\n",
    "    return np.concatenate([X_other, neighborhood_encoded, exterQual_encoded], axis=1)\n",
    "\n",
    "X_train_encoded = one_hot_encode_X(X_train)\n",
    "X_dev_encoded = one_hot_encode_X(X_dev)\n",
    "\n",
    "reg.fit(X_train_encoded, y_train)\n",
    "y_dev_hat = reg.predict(X_dev_encoded)\n",
    "print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class ValueEncoder:\n",
    "    \n",
    "    def __init__(self, cat_colname=None, value_colname=None, agg_function='mean',):\n",
    "        self.agg_function = agg_function\n",
    "        self.cat_colname = cat_colname if cat_colname is not None else\\\n",
    "            ''.join(np.random.choice(list(string.ascii_lowercase + string.digits)) for _ in range(10))\n",
    "        self.value_colname = value_colname if value_colname is not None else\\\n",
    "            self.cat_colname + \"_\" + self.agg_function\n",
    "        self.cat_value_df = None\n",
    "            \n",
    "    def fit(self, cat_series, value_series):\n",
    "        cat_value_df = pd.DataFrame({\n",
    "            self.cat_colname: cat_series,\n",
    "            self.value_colname: value_series\n",
    "        })\n",
    "        self.cat_value_df = cat_value_df\\\n",
    "            .groupby(self.cat_colname, as_index=False)\\\n",
    "            .agg(self.agg_function)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, cat_series):\n",
    "        return pd.DataFrame({self.cat_colname:cat_series})\\\n",
    "            .merge(self.cat_value_df, on=self.cat_colname, how=\"left\")[self.value_colname]\n",
    "\n",
    "value_encoder_Neighborhood = ValueEncoder(\"Neighborhood\")\\\n",
    "   .fit(X_train[\"Neighborhood\"], y_train)  \n",
    "value_encoder_ExterQual = ValueEncoder(\"ExterQual\")\\\n",
    "   .fit(X_train[\"ExterQual\"], y_train)\n",
    "\n",
    "def value_encode_X(X):\n",
    "    encoded_X = X.drop([\"Neighborhood\", \"ExterQual\"], axis=1).reset_index(drop=True)\n",
    "    encoded_X[\"Neighborhood_encoded\"] = value_encoder_Neighborhood.transform(X[\"Neighborhood\"])\n",
    "    encoded_X[\"ExterQual_encoded\"] = value_encoder_ExterQual.transform(X[\"ExterQual\"])\n",
    "    return encoded_X\n",
    "\n",
    "X_train_encoded = value_encode_X(X_train)\n",
    "X_dev_encoded = value_encode_X(X_dev)\n",
    "reg.fit(X_train_encoded, y_train)\n",
    "y_dev_hat = reg.predict(X_dev_encoded)\n",
    "print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = \"LotShape\"\n",
    "classes = X[colname].unique()\n",
    "col2num = {classes[i]: i for i in range(len(classes))}\n",
    "X_train[colname + \"_int\"] = X_train[colname].apply(lambda cls: col2num[cls])\n",
    "X_dev[colname + \"_int\"] = X_dev[colname].apply(lambda cls: col2num[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_one_hot_encoding(series, dict_length=None):\n",
    "    if dict_length is None:\n",
    "        dict_length = len(series.unique())\n",
    "    return np.eye(dict_length)[series]\n",
    "    \n",
    "label_one_hot_encoding(animals_df[\"name_label\"], len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def test_column(colname):\n",
    "    classes = X[colname].unique()\n",
    "    col2num = {classes[i]: i for i in range(len(classes))}\n",
    "    X_train[colname + \"_int\"] = X_train[colname].apply(lambda cls: col2num[cls])\n",
    "    X_dev[colname + \"_int\"] = X_dev[colname].apply(lambda cls: col2num[cls])\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train[[colname + \"_int\"]], y_train)\n",
    "    y_dev_hat = reg.predict(X_dev[[colname + \"_int\"]])\n",
    "    print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)))\n",
    "\n",
    "for colname in categorical_columns:\n",
    "    print(\"----------------\")\n",
    "    print(colname)\n",
    "    test_column(colname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_column(colname):\n",
    "    classes = X[colname].unique()\n",
    "    col2num = {classes[i]: i for i in range(len(classes))}\n",
    "    X_train[colname + \"_int\"] = X_train[colname].apply(lambda cls: col2num[cls])\n",
    "    X_dev[colname + \"_int\"] = X_dev[colname].apply(lambda cls: col2num[cls])\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(label_one_hot_encoding( X_train[colname + \"_int\"], dict_length=len(classes)), y_train)\n",
    "    y_dev_hat = reg.predict(label_one_hot_encoding(X_dev[colname + \"_int\"], dict_length=len(classes)))\n",
    "    print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)))\n",
    "\n",
    "for colname in categorical_columns:\n",
    "    print(\"----------------\")\n",
    "    print(colname)\n",
    "    test_column(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/titanic/train.csv\", index_col=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Survived\", axis=1)\n",
    "y = data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, random_state=666, test_size=0.2)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, random_state=667, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survived based on sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_df = X_train[[\"Sex\", \"Name\"]].copy()\n",
    "sex_df[\"Survived\"] = y_train\n",
    "\n",
    "sex_df.reset_index().groupby([\"Sex\", \"Survived\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexes = [\"male\", \"female\"]\n",
    "sex2num = {sexes[i]: i for i in range(len(sexes))}\n",
    "\n",
    "sex_encoded = X_dev[\"Sex\"].apply(lambda sex: sex2num.get(sex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy :\", accuracy_score(y_dev, y_dev_hat))\n",
    "print(\"f1-score: \", f1_score(y_dev, sex_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passenger class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.groupby(\"Pclass\")[\"Name\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex_pclass_transform(X):\n",
    "    new_X = X[['Pclass']].copy()\n",
    "    new_X = X[['SibSp']].copy()\n",
    "    #new_X[\"sex\"] = X[\"Sex\"].apply(lambda sex: sex2num.get(sex))\n",
    "    return new_X\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(sex_pclass_transform(X_train), y_train)\n",
    "y_dev_hat = clf.predict(sex_pclass_transform(X_dev))\n",
    "print(\"Accuracy :\", accuracy_score(y_dev, y_dev_hat))\n",
    "print(\"f1-score: \", f1_score(y_dev, sex_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    clf, out_file=None, \n",
    "    feature_names=sex_pclass_transform(X_train).columns.values,  \n",
    "    class_names=[\"Not survived\", \"survived\"],  \n",
    "    filled=True, rounded=True,  \n",
    "    special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(sex_pclass_transform(X_train), y_train)\n",
    "y_dev_hat = clf.predict(sex_pclass_transform(X_dev))\n",
    "print(\"Accuracy :\", accuracy_score(y_dev, y_dev_hat))\n",
    "print(\"f1-score: \", f1_score(y_dev, sex_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"SibSp\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_targets = np.eye(nb_classes)[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = array(data)\n",
    "print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
